# -*- coding: utf-8 -*-
"""Machine Vision Group Assignment Balls 10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-KIRKmFXsE4EJz_dQ2rIIhyTHxjInjH_
"""

# Importing the necessary libraries
import torch
from torch import nn

import torchvision
from torchvision import datasets, models
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt


# Mount Google Drive to access your data (We're using Google Colab)
from google.colab import drive
drive.mount('/content/drive')


# Define data transformations for image preprocessing
transform = transforms.Compose(
    [ transforms.Resize((224,224)), # Resize images to 224x224
      transforms.CenterCrop(224), # Center crop to 224x224
      transforms.ToTensor(), # this to convert the images to 4D matrix (B,C,H,W)
      transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))] # Normalize images with mean and std deviation
)

# Define directories for train and test datasets
train_dir = '/content/drive/MyDrive/Machine Vision Group Assignment/Balls_10/train'
test_dir = '/content/drive/MyDrive/Machine Vision Group Assignment/Balls_10/test'

# Create datasets with the defined transformations
train_data = datasets.ImageFolder(root = train_dir,transform = transform)
test_data = datasets.ImageFolder(root = test_dir,transform = transform)

class_names = train_data.classes # Get class names from the dataset
train_data.classes

# Create data loaders for training and testing
from torch.utils.data import DataLoader
BATCH_SIZE = 4
train_dataloader = DataLoader(train_data,batch_size=BATCH_SIZE, shuffle=True)
test_dataloader = DataLoader(test_data,batch_size=BATCH_SIZE, shuffle=False)

# Print information about data loaders
print(f"Dataloaders: {train_dataloader, test_dataloader}")
print(f"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}")
print(f"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}")

import numpy as np
import matplotlib.pyplot as plt

# Function to display images
def show_image(img):
    img = img / 2 + 0.5     # Unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# Get some random training images and display them
dataiter = iter(train_dataloader)
images, labels = next(dataiter)

show_image(torchvision.utils.make_grid(images)) # show images
print(' '.join('%5s' % class_names[labels[j]] for j in range(4))) # print labels

# Define the CNN model
class CNNModel(nn.Module):

    def __init__(self):
      super(CNNModel,self).__init__()

      # Define the layers of the convolutional neural network
      # Convolutional layers with specified input and output channels and kernel sizes
      self.conv1= nn.Conv2d(3,6,5) # Input: 3 channels (RGB), Output: 6 channels, Kernel Size: 5x5
      self.conv2 = nn.Conv2d(6,16,5) # Input: 6 channels, Output: 16 channels, Kernel Size: 5x5
      self.conv3 = nn.Conv2d(16,20,3) # Input: 16 channels, Output: 20 channels, Kernel Size: 3x3

      # Max-pooling layers to reduce spatial dimensions
      self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2)
      self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride=2)
      self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride=2)

      # Fully connected layers (linear layers)  
      self.fc1 = nn.Linear(20*25*25,100) # Input size calculated based on previous layers, output size: 100
      self.fc2 = nn.Linear(100,10)  # Output size: 10 (assuming 10 classes)
      self.flatten= nn.Flatten() # Flatten layer to convert 3D data to 1D data before fully connected layers

      # Batch normalization layers for improving training stability
      self.batchnorm1 = nn.BatchNorm2d(6)
      self.batchnorm2 = nn.BatchNorm2d(16)
      self.batchnorm3 = nn.BatchNorm2d(20)
      self.dropout = nn.Dropout(0.4) # Dropout layer to prevent overfitting. Dropout rate: 40%
      self.relu = nn.ReLU() # ReLU activation function to introduce non-linearity


    def forward(self,x):
      # Define the forward pass of the network
      x = self.conv1(x)
      x = self.relu(x)
      x = self.batchnorm1(x) 
      x = self.maxpool1(x)
      x = self.conv2(x)
      x = self.relu(x)
      x = self.batchnorm2(x)
      x = self.maxpool2(x)
      x = self.conv3(x)
      x = self.relu(x)
      x = self.batchnorm3(x)
      x = self.maxpool3(x)
      x = self.flatten(x)
      x = self.fc1(x)
      x = self.dropout(x)
      x = self.relu(x)
      out = self.fc2(x) # Final output after passing through fully connected layers

      return out

model = CNNModel() # Create an instance of the CNN model

model.train() # Set the model to training mode

# Install torchinfo for model summary
!pip install torchinfo

from torchinfo import summary

summary(model) # Display the model summary

# Define loss function and optimizer
loss_fn = nn.CrossEntropyLoss()#cross-entropy
optimizer = torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9) # Stochastic Gradient Descent

model.to('cuda') # Move the model to the GPU if available


import time
from tqdm.auto import tqdm

# Function to train and validate the model
def train_and_validate(model, loss_criterion, optimizer, train_dataloader, test_dataloader, epochs=25, device='cuda'):
    '''
    Function to train and validate
    Parameters
        :param model: Model to train and validate
        :param loss_criterion: Loss Criterion to minimize
        :param optimizer: Optimizer for computing gradients
        :param train_dataloader: DataLoader for training data
        :param test_dataloader: DataLoader for test/validation data
        :param epochs: Number of epochs (default=25)
        :param device: Device to perform computations ('cuda' or 'cpu')

    Returns
        model: Trained Model with best validation accuracy
        history: (dict object): Having training loss, accuracy and validation loss, accuracy
    '''

    start = time.time()
    history = []
    best_acc = 0.0

    for epoch in tqdm(range(epochs)):
        epoch_start = time.time()
        print("Epoch: {}/{}".format(epoch+1, epochs))

        model.train()

        train_loss = 0.0
        train_acc = 0.0

        valid_loss = 0.0
        valid_acc = 0.0

        for i, (inputs, labels) in enumerate(train_dataloader):

            inputs = inputs.to(device)
            labels = labels.to(device)

            # Clean existing gradients
            optimizer.zero_grad()

            # Forward pass - compute outputs on input data using the model
            outputs = model(inputs)

            # Compute loss
            loss = loss_criterion(outputs, labels)

            # Backpropagate the gradients
            loss.backward()

            # Update the parameters
            optimizer.step()

            # Compute the total loss for the batch and add it to train_loss
            train_loss += loss.item() * inputs.size(0)

            # Compute the accuracy
            ret, predictions = torch.max(outputs.data, 1)
            correct_counts = predictions.eq(labels.data.view_as(predictions))

            # Convert correct_counts to float and then compute the mean
            acc = torch.mean(correct_counts.type(torch.FloatTensor))

            # Compute total accuracy in the whole batch and add to train_acc
            train_acc += acc.item() * inputs.size(0)

        # Validation - No gradient tracking needed
        with torch.no_grad():

            model.eval()

            # Validation loop
            for j, (inputs, labels) in enumerate(test_dataloader):
                inputs = inputs.to(device)
                labels = labels.to(device)

                # Forward pass - compute outputs on input data using the model
                outputs = model(inputs)

                # Compute loss
                loss = loss_criterion(outputs, labels)

                # Compute the total loss for the batch and add it to valid_loss
                valid_loss += loss.item() * inputs.size(0)

                # Calculate validation accuracy
                ret, predictions = torch.max(outputs.data, 1)
                correct_counts = predictions.eq(labels.data.view_as(predictions))

                # Convert correct_counts to float and then compute the mean
                acc = torch.mean(correct_counts.type(torch.FloatTensor))

                # Compute total accuracy in the whole batch and add to valid_acc
                valid_acc += acc.item() * inputs.size(0)


        # Find average training loss and training accuracy
        avg_train_loss = train_loss / len(train_dataloader.dataset)
        avg_train_acc = train_acc / len(train_dataloader.dataset)

        # Find average validation loss and training accuracy
        avg_test_loss = valid_loss / len(test_dataloader.dataset)
        avg_test_acc = valid_acc / len(test_dataloader.dataset)

        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])

        epoch_end = time.time()

        print("Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \n\t\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s".format(epoch, avg_train_loss, avg_train_acc * 100, avg_test_loss, avg_test_acc * 100, epoch_end - epoch_start))

        # Save if the model has best accuracy till now
        if avg_test_acc > best_acc:
            best_acc = avg_test_acc
            best_model = model
            torch.save(best_model, 'best_model.pt')

    return best_model, history

import torch
# Check if CUDA (GPU) is available
if torch.cuda.is_available():
    print("CUDA is available. You can use GPU.")
else:
    print("CUDA is not available. You can only use CPU.")

num_epochs = 10
trained_model, history = train_and_validate(model,loss_fn,optimizer,train_dataloader,test_dataloader,num_epochs)

# Plot the loss curve
def plot_loss(history):
  history = np.array(history)
  plt.plot(history[:,0:2])
  plt.legend(['Tr Loss', 'Val Loss'])
  plt.xlabel('Epoch Number')
  plt.ylabel('Loss')
  plt.ylim(0,3)
  plt.show()

plot_loss(history)

# Plot the accuracy curve
def plot_accuracy(history):
  history = np.array(history)
  plt.plot(history[:,2:4])
  plt.legend(['Tr Accuracy', 'Val Accuracy'])
  plt.xlabel('Epoch Number')
  plt.ylabel('Accuracy')
  plt.ylim(0,1)
  plt.show()

plot_accuracy(history)

from sklearn.metrics import confusion_matrix
import seaborn as sn
import pandas as pd

# Function to plot the confusion matrix
def plot_confusionMatrix(model, test_dataloader):

  y_pred = []
  y_true = []

  model.to('cpu')

  # Iterates over test data
  for inputs, labels in test_dataloader:
          output = model(inputs) # Feed Network

          output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
          y_pred.extend(output) # Save Prediction

          labels = labels.data.cpu().numpy()
          y_true.extend(labels) # Save Truth

  # Build confusion matrix
  cf_matrix = confusion_matrix(y_true, y_pred)
  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in class_names],
                      columns = [i for i in class_names])
  plt.figure(figsize = (20,10))
  sn.heatmap(df_cm, annot=True)

plot_confusionMatrix(model, test_dataloader)

